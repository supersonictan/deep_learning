{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import math\n",
    "from datetime import datetime\n",
    "import multiprocessing\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import data\n",
    "from tensorflow.python.feature_column import feature_column\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "MODEL_NAME = 'cenus-model-01'\n",
    "TRAIN_DATA_FILES_PATTERN = 'adult_train.csv'\n",
    "TEST_DATA_FILES_PATTERN = 'adult_test.csv'\n",
    "RESUME_TRAINING = False\n",
    "PROCESS_FEATURES = True\n",
    "EXTEND_FEATURE_COLUMNS = True\n",
    "MULTI_THREADING = True\n",
    "\n",
    "\"\"\"\n",
    "# 特征列名: HEADER\n",
    "# 特征默认值: HEADER_DEFAULTS\n",
    "# 数值型的列名: NUMERIC_FEATURE_NAMES\n",
    "# 类别型的列，把列的不同取值列出来: CATEGORICAL_FEATURE_NAMES_WITH_VOCABULARY\n",
    "# hash分桶列: CATEGORICAL_FEATURE_NAMES_WITH_BUCKET_SIZE\n",
    "# 类别型的列名: CATEGORICAL_FEATURE_NAMES\n",
    "# 总的列名: FEATURE_NAMES\n",
    "# 目标列名: TARGET_NAME\n",
    "# 目标不同类别的取值: TARGET_LABELS\n",
    "# 权重列: WEIGHT_COLUMN_NAME\n",
    "# 没有用到的列: UNUSED_FEATURE_NAMES\n",
    "\"\"\"\n",
    "HEADER = ['age', 'workclass', 'fnlwgt', 'education', 'education_num','marital_status', 'occupation', 'relationship', 'race', 'gender', 'capital_gain', 'capital_loss', 'hours_per_week','native_country', 'income_bracket']\n",
    "HEADER_DEFAULTS = [[0], [''], [0], [''], [0], [''], [''], [''], [''], [''],[0], [0], [0], [''], ['']]\n",
    "NUMERIC_FEATURE_NAMES = ['age', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
    "CATEGORICAL_FEATURE_NAMES_WITH_VOCABULARY = {\n",
    "    'gender': ['Female', 'Male'],\n",
    "    'race': ['Amer-Indian-Eskimo', 'Asian-Pac-Islander', 'Black', 'Other', 'White'],\n",
    "    'education': ['Bachelors', 'HS-grad', '11th', 'Masters', '9th', 'Some-college','Assoc-acdm', 'Assoc-voc', '7th-8th', 'Doctorate', 'Prof-school', '5th-6th', '10th', '1st-4th', 'Preschool', '12th'],\n",
    "    'marital_status': ['Married-civ-spouse', 'Divorced', 'Married-spouse-absent', 'Never-married', 'Separated', 'Married-AF-spouse', 'Widowed'],\n",
    "    'relationship': ['Husband', 'Not-in-family', 'Wife', 'Own-child', 'Unmarried', 'Other-relative'],\n",
    "    'workclass': ['Self-emp-not-inc', 'Private', 'State-gov', 'Federal-gov', 'Local-gov', '?', 'Self-emp-inc', 'Without-pay', 'Never-worked']\n",
    "}\n",
    "CATEGORICAL_FEATURE_NAMES_WITH_BUCKET_SIZE = {'occupation': 50, 'native_country': 100}\n",
    "CATEGORICAL_FEATURE_NAMES = list(CATEGORICAL_FEATURE_NAMES_WITH_VOCABULARY.keys()) + list(CATEGORICAL_FEATURE_NAMES_WITH_BUCKET_SIZE.keys())\n",
    "FEATURE_NAMES = NUMERIC_FEATURE_NAMES + CATEGORICAL_FEATURE_NAMES\n",
    "TARGET_NAME = 'income_bracket'\n",
    "TARGET_LABELS = ['<=50K', '>50K']\n",
    "WEIGHT_COLUMN_NAME = 'fnlwgt'\n",
    "UNUSED_FEATURE_NAMES = list(set(HEADER) - set(FEATURE_NAMES) - {TARGET_NAME} - {WEIGHT_COLUMN_NAME})\n",
    "\n",
    "print(\"全部列名: {}\".format(HEADER))\n",
    "print(\"数值型的特征: {}\".format(NUMERIC_FEATURE_NAMES))\n",
    "print(\"类别型的特征: {}\".format(CATEGORICAL_FEATURE_NAMES))\n",
    "print(\"目标列: {} - 不同的分类结果: {}\".format(TARGET_NAME, TARGET_LABELS))\n",
    "print(\"没有用到的列: {}\".format(UNUSED_FEATURE_NAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 数据统计\n",
    "train_data = pd.read_csv('adult_train.csv', header=None, names=HEADER )\n",
    "means = train_data[NUMERIC_FEATURE_NAMES].mean(axis=0)\n",
    "stdvs = train_data[NUMERIC_FEATURE_NAMES].std(axis=0)\n",
    "maxs = train_data[NUMERIC_FEATURE_NAMES].max(axis=0)\n",
    "mins = train_data[NUMERIC_FEATURE_NAMES].min(axis=0)\n",
    "df_stats = pd.DataFrame({\"mean\":means, \"stdv\":stdvs, \"max\":maxs, \"min\":mins})\n",
    "\n",
    "df_stats.to_csv(path_or_buf=\"adult.stats.csv\", header=True, index=True)\n",
    "df_stats.head(15)\n",
    "# train_data.head(3)\n",
    "# train_data.info()\n",
    "# train_data.describe()\n",
    "# TRAIN_DATA_SIZE = train_data.shape[0]  # 32561\n",
    "# test_data = pd.read_csv(TEST_DATA_FILES_PATTERN, skiprows=1)\n",
    "# TEST_DATA_SIZE = test_data.shape[0]  # 16279\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征构造\n",
    "# 没用\n",
    "def process_features(features):\n",
    "    # 判断，字典中新的key capital_indicator也同样对应一个tensor\n",
    "    capital_indicator = features['capital_gain'] > features['capital_loss']\n",
    "    features['capital_indicator'] = tf.cast(capital_indicator, dtype=tf.int32)\n",
    "    # 返回feature字典\n",
    "    return features\n",
    "\n",
    "def parse_csv_row(csv_row):\n",
    "    columns = tf.decode_csv(csv_row, record_defaults=HEADER_DEFAULTS)\n",
    "    features = dict(zip(HEADER, columns))  # 把tensor和对应的列名打包成字典\n",
    "    \n",
    "    for column in UNUSED_FEATURE_NAMES:  # 去除无用的列\n",
    "        features.pop(column)\n",
    "\n",
    "    target = features.pop('income_bracket')  # 取出目标列\n",
    "    \n",
    "    return features, target  # 返回 字典+target序列形式\n",
    "\n",
    "def csv_input_fn(file_names, mode=tf.estimator.ModeKeys.EVAL, skip_header_lines=0, num_epochs=None, batch_size=200):\n",
    "    shuffle = True if mode == tf.estimator.ModeKeys.TRAIN else False  # 训练阶段数据要shuffle，测试阶段不用\n",
    "\n",
    "    num_threads = multiprocessing.cpu_count() if MULTI_THREADING else 1  # 多线程\n",
    "    \n",
    "    dataset = data.TextLineDataset(filenames=file_names)\n",
    "    dataset = dataset.skip(0)  # 跳过第一行\n",
    "    \n",
    "    # 乱序\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=2 * batch_size + 1)\n",
    "    \n",
    "    # 取一个batch\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    # 对数据进行解析\n",
    "    dataset = dataset.map(lambda csv_row: parse_csv_row(csv_row), num_parallel_calls=num_threads)\n",
    "    \n",
    "    # 每个epoch完成后，重启dataset  \n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    # 取出满足 特征字典+结果序列 的值\n",
    "    features, target = iterator.get_next()\n",
    "    return features, target\n",
    "\n",
    "features, target = csv_input_fn(file_names=[\"./adult_train.csv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extend_feature_columns(feature_columns, hparams):\n",
    "    \n",
    "    # 年龄分桶\n",
    "    age_buckets = tf.feature_column.bucketized_column(feature_columns['age'], boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])\n",
    "    \n",
    "    # 特征交叉组合并hash分桶\n",
    "    education_X_occupation = tf.feature_column.crossed_column(['education', 'occupation'], hash_bucket_size=int(1e4))\n",
    "    \n",
    "    # 特征交叉组合并hash分桶\n",
    "    age_buckets_X_race = tf.feature_column.crossed_column([age_buckets, feature_columns['race']], hash_bucket_size=int(1e4))\n",
    "    \n",
    "    # 特征交叉组合并hash分桶\n",
    "    native_country_X_occupation = tf.feature_column.crossed_column(['native_country', 'occupation'], hash_bucket_size=int(1e4))\n",
    "    \n",
    "    # 对类别型特征做embedding\n",
    "    native_country_embedded = tf.feature_column.embedding_column(feature_columns['native_country'], dimension=hparams['embedding_size'])\n",
    "    \n",
    "    # 对类别型特征做embedding\n",
    "    occupation_embedded = tf.feature_column.embedding_column(feature_columns['occupation'], dimension=hparams['embedding_size'])\n",
    "    \n",
    "    # 同上\n",
    "    education_X_occupation_embedded = tf.feature_column.embedding_column(education_X_occupation, dimension=hparams['embedding_size'])\n",
    "    \n",
    "    # 同上\n",
    "    native_country_X_occupation_embedded = tf.feature_column.embedding_column(native_country_X_occupation, dimension=hparams['embedding_size'])\n",
    "    \n",
    "    # 构建feature columns\n",
    "    feature_columns['age_buckets'] = age_buckets\n",
    "    feature_columns['education_X_occupation'] = education_X_occupation\n",
    "    feature_columns['age_buckets_X_race'] = age_buckets_X_race\n",
    "    feature_columns['native_country_X_occupation'] = native_country_X_occupation\n",
    "    feature_columns['native_country_embedded'] = native_country_embedded\n",
    "    feature_columns['occupation_embedded'] = occupation_embedded\n",
    "    feature_columns['education_X_occupation_embedded'] = education_X_occupation_embedded\n",
    "    feature_columns['native_country_X_occupation_embedded'] = native_country_X_occupation_embedded\n",
    "    \n",
    "    # 返回feature_columns字典\n",
    "    return feature_columns\n",
    "\n",
    "# 标准化\n",
    "def standard_scaler(x, mean, stdv):\n",
    "    return (x-mean)/(stdv)\n",
    "\n",
    "# 最大最小值幅度缩放\n",
    "def maxmin_scaler(x, max_value, min_value):\n",
    "    return (x-min_value)/(max_value-min_value)\n",
    "\n",
    "\n",
    "\n",
    "# 全部的特征\n",
    "def get_feature_columns(hparams):\n",
    "    \n",
    "    # 数值型的列\n",
    "    numeric_columns = {}\n",
    "    # 对数值型的列做幅度缩放(scaling)\n",
    "    for feature_name in NUMERIC_FEATURE_NAMES:\n",
    "\n",
    "        feature_mean = df_stats[df_stats.feature_name == feature_name]['mean'].values[0]\n",
    "        feature_stdv = df_stats[df_stats.feature_name == feature_name]['stdv'].values[0]\n",
    "        normalizer_fn = lambda x: standard_scaler(x, feature_mean, feature_stdv)\n",
    "        \n",
    "        numeric_columns[feature_name] = tf.feature_column.numeric_column(feature_name, normalizer_fn=normalizer_fn)\n",
    "    # 新构建列(这里没有)                                                                  \n",
    "    CONSTRUCTED_NUMERIC_FEATURES_NAMES = []\n",
    "    \n",
    "    if PROCESS_FEATURES:\n",
    "        for feature_name in CONSTRUCTED_NUMERIC_FEATURES_NAMES:\n",
    "            numeric_columns[feature_name] = tf.feature_column.numeric_column(feature_name)\n",
    "    \n",
    "    # 对类别型的列做独热向量编码\n",
    "    categorical_column_with_vocabulary = \\\n",
    "        {item[0]: tf.feature_column.categorical_column_with_vocabulary_list(item[0], item[1])\n",
    "         for item in CATEGORICAL_FEATURE_NAMES_WITH_VOCABULARY.items()}\n",
    "    \n",
    "    # indicator列，multi-hot编码\n",
    "    CONSTRUCTED_INDICATOR_FEATURES_NAMES = ['capital_indicator']\n",
    "    \n",
    "    categorical_column_with_identity = {}\n",
    "    \n",
    "    for feature_name in CONSTRUCTED_INDICATOR_FEATURES_NAMES: \n",
    "        categorical_column_with_identity[feature_name] = tf.feature_column.categorical_column_with_identity(feature_name, \n",
    "                                                                                                              num_buckets=2,\n",
    "                                                                                                            default_value=0)\n",
    "    # 类别型进行hash分桶映射                                                                                                          \n",
    "    categorical_column_with_hash_bucket = \\\n",
    "        {item[0]: tf.feature_column.categorical_column_with_hash_bucket(item[0], item[1], dtype=tf.string)\n",
    "         for item in CATEGORICAL_FEATURE_NAMES_WITH_BUCKET_SIZE.items()}\n",
    "        \n",
    "    feature_columns = {}\n",
    "\n",
    "    # 更新数值列                                                                                                        \n",
    "    if numeric_columns is not None:\n",
    "        feature_columns.update(numeric_columns)\n",
    "\n",
    "    # 更新独热向量编码列\n",
    "    if categorical_column_with_vocabulary is not None:\n",
    "        feature_columns.update(categorical_column_with_vocabulary)\n",
    "    \n",
    "    # 更新label encoder列\n",
    "    if categorical_column_with_identity is not None:\n",
    "        feature_columns.update(categorical_column_with_identity)\n",
    "                                                                                                            \n",
    "    # 更新类别型hash分桶列    \n",
    "    if categorical_column_with_hash_bucket is not None:\n",
    "        feature_columns.update(categorical_column_with_hash_bucket)\n",
    "                                                                                                            \n",
    "    # 扩充tf产出的高级列\n",
    "    if EXTEND_FEATURE_COLUMNS:\n",
    "        feature_columns = extend_feature_columns(feature_columns, hparams)\n",
    "                                                                                                            \n",
    "    # 返回feature columns   \n",
    "    return feature_columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
